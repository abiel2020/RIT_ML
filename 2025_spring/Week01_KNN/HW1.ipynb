{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Homework 1: kNN (20pt)\n",
        "In this HW, you will write the $k$ Nearest Neighbors algorithm and run it on the synthetical data. Then, you will use the built-in function from *sklearn* library."
      ],
      "metadata": {
        "id": "p2tvk5Tm_6Ah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part I. Vanilla $k$NN (17.5pt)"
      ],
      "metadata": {
        "id": "oSAbmL4kRmM1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONzZa7M2zYGG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "import time\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "#import other modules here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic dataset with 2 classes\n",
        "X, y = make_classification(n_samples=300, n_features=2, n_redundant=0, random_state=31)"
      ],
      "metadata": {
        "id": "0w6lyi0ZzgVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. (0.5pt) Check the shapes of $X$ and $y$"
      ],
      "metadata": {
        "id": "I1kNqtwDHXR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here\n"
      ],
      "metadata": {
        "id": "lKRFsq1kH6TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the synthetic dataset\n",
        "scatter_train = plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Synthetic 2D Dataset with Two Classes')\n",
        "plt.legend(handles=scatter_train.legend_elements()[0], labels=['Class 0', 'Class 1'])"
      ],
      "metadata": {
        "id": "LC2TjPCqQoUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. (1pt) Split the data into train and test sets. You can use a built-in [function train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from sklearn. (To get the same result as in the lecture slides, use the parameters from the example in the description of the function.)"
      ],
      "metadata": {
        "id": "uNLcPV14IWB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = #your code here"
      ],
      "metadata": {
        "id": "8BjjwkmoEcg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the synthetic dataset again\n",
        "scatter_train = plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=plt.cm.Paired)\n",
        "scatter_test = plt.scatter(X_test[:, 0], X_test[:, 1], c='black', marker='x')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Synthetic 2D Dataset with Two Classes')\n",
        "plt.legend(handles=scatter_train.legend_elements()[0]+[scatter_test], labels=['Class 0', 'Class 1', 'Test'])"
      ],
      "metadata": {
        "id": "KfkGHE4Fzu21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. (9pt) Fill-in the functions *compute_distances_two_loops*, *compute_distances_one_loop*, and *predict_labels* of the followng class. Use $L_1$ (Manhattan) distance:\n",
        "$$\n",
        "d(x,\\ x^{(i)}) =\\sum_{j=1}^{d} |x_j-x^{(i)}_j|.\n",
        "$$"
      ],
      "metadata": {
        "id": "YzMcMzJ5Rkl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class kNNClassifier:\n",
        "  def __init__(self, k=1, n_loops=2):\n",
        "     self.k = k\n",
        "     self.n_loops = n_loops\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.train_X = X\n",
        "    self.train_y = y\n",
        "\n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    X np array (n_samples, n_features)\n",
        "    returns predicted class for each sample: np array (n_samples)\n",
        "    \"\"\"\n",
        "    if self.n_loops == 2:\n",
        "      distances = self.compute_distances_two_loops(X)\n",
        "    elif self.n_loops == 1:\n",
        "      distances = self.compute_distances_one_loop(X)\n",
        "    return self.predict_labels(distances)\n",
        "\n",
        "  def compute_distances_two_loops(self, X):\n",
        "    \"\"\"\n",
        "    X np array (n_samples, n_features)\n",
        "    returns distances between each test sampla and each train sample: np array (n_test_samples, n_train_samples)\n",
        "    \"\"\"\n",
        "    #your code here\n",
        "\n",
        "  def compute_distances_one_loop(self, X): #or without for loops at all (see ML2 problems)\n",
        "    \"\"\"\n",
        "    X np array (n_samples, n_features)\n",
        "    returns distances between each test sampla and each train sample: np array (n_test_samples, n_train_samples)\n",
        "    \"\"\"\n",
        "    #your code here\n",
        "\n",
        "  def predict_labels(self, distances):\n",
        "    \"\"\"\n",
        "    distances: np array (n_test_samples, n_train_samples)\n",
        "    output: np array (n_test_samples,)\n",
        "    \"\"\"\n",
        "    #your code here"
      ],
      "metadata": {
        "id": "gGyXSQgWz5EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Fit the model with 2 for loops (one neighbor)"
      ],
      "metadata": {
        "id": "sVjWFBWcGJdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create an object of the class above\n",
        "clf_2 = kNNClassifier()"
      ],
      "metadata": {
        "id": "Dyf3dc73RwJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model on the training data\n",
        "clf_2.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "0uBPXmbSR3O3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Fit the model with 1 for loop"
      ],
      "metadata": {
        "id": "NWNrJ_7LGdt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create an object of the class above\n",
        "clf_1 = kNNClassifier(n_loops=1)"
      ],
      "metadata": {
        "id": "WQqvCYvvGdt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model on the training data\n",
        "clf_1.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "kuViz-TcGdt4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6a). (0.5pt) Make a prediction on the points with coordinates $(0, -2)$"
      ],
      "metadata": {
        "id": "blBmJo_8G2X9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JNWKmniMSR3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6b). (0.5pt) Make a prediction on the points with coordinates $(0, 2)$"
      ],
      "metadata": {
        "id": "_tRJLL5kI1PU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1UiBiJC2Iy6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Plot the decision boundary. You can use function [plot_decision_regions](https://rasbt.github.io/mlxtend/api_subpackages/mlxtend.plotting/#plot_decision_regions)"
      ],
      "metadata": {
        "id": "smsTgAseJ6Lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "plot_decision_regions(X_train,y_train,clf_1)\n",
        "end_time = time.time()\n",
        "end_time - start_time"
      ],
      "metadata": {
        "id": "Ct5rljlsVBuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#You may whant to compare the performance with loops\n",
        "start_time = time.time()\n",
        "plot_decision_regions(X_train,y_train,clf_2)\n",
        "end_time = time.time()\n",
        "end_time - start_time"
      ],
      "metadata": {
        "id": "MbOfR_HCiH2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. (2.5pt) Now, use the built-in class [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). Think about what parameter to use in order to get the same plot as above."
      ],
      "metadata": {
        "id": "okzW1_U4Mo10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_3 = # your code here"
      ],
      "metadata": {
        "id": "sf_Cg0hVOydY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model on the training data\n",
        "clf_3.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "ls2ZJlrMM04W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "plot_decision_regions(X_train,y_train,clf_3)\n",
        "end_time = time.time()\n",
        "end_time - start_time"
      ],
      "metadata": {
        "id": "VoMFcx-zM04a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. (3pt) Choose $k.$  Write a for loop over 40 values of $k,$ for every $k$ train the fastest model on the train data and make prediction on the train and on the test data and store the accuracy on both sets. Plot the curves similar to ones in Lecture 2. To calculate accuracy you can use function [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score).  "
      ],
      "metadata": {
        "id": "OvzP9iUcORZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fifZWBRqQnes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQAK9JAZQnwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. For the 'best' $k$ plot the desicion boundary."
      ],
      "metadata": {
        "id": "bE0NfMihQpSo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c9kgARYCQ3XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. (0.5pt) Does the algorithm this this $k$ do a good job?"
      ],
      "metadata": {
        "id": "zBWgy1bjQ38L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part II. Weighted $k$NN (2.5pt)"
      ],
      "metadata": {
        "id": "SOUbjDniRQqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. (1.5pt) Modify the *predict_labels* function so that the score for class $c$ is calculated as follows:\n",
        "$$\n",
        "q(x)=\\sum_{i=1}^{k}[y^{(i)}=c] \\cdot \\frac{1}{1+d(x,\\ x^{(i)})}\n",
        "$$\n",
        "and the class with highest value of $q(x)$ is chosen as the label."
      ],
      "metadata": {
        "id": "wnZD1pmQR_5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class kNNClassifier_w:\n",
        "  def __init__(self, k=1):\n",
        "     self.k = k\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.train_X = X\n",
        "    self.train_y = y\n",
        "\n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    X np array (n_samples, n_features)\n",
        "    returns predicted class for each sample: np array (n_samples)\n",
        "    \"\"\"\n",
        "    distances = self.compute_distances(X)\n",
        "    return self.predict_labels(distances)\n",
        "\n",
        "  def compute_distances(self, X):\n",
        "    \"\"\"\n",
        "    X np array (n_samples, n_features)\n",
        "    returns distances between each test sampla and each train sample: np array (n_test_samples, n_train_samples)\n",
        "    \"\"\"\n",
        "    #thake the best from Part I\n",
        "\n",
        "  def predict_labels(self, distances):\n",
        "    labels = np.zeros(len(distances))\n",
        "    #your code here\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "3FY4am8g6P7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Run this algorithm for $k=3$ and plot the desicion boundary."
      ],
      "metadata": {
        "id": "l9aPU3w2T2Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_w = kNNClassifier_w(k=3)"
      ],
      "metadata": {
        "id": "WBP_30G86P7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_w.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "VKQSz7If6P7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_decision_regions(X_train,y_train,clf_w)"
      ],
      "metadata": {
        "id": "G39XHcob6P7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. (1pt) Use the buit-in algorithm with collable function"
      ],
      "metadata": {
        "id": "UU33zedyUVzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func(d):\n",
        "  return sum(1/(1+d))"
      ],
      "metadata": {
        "id": "KRVl5g3x00e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qPSEaLdsED2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Does the desicion boundary look the same? You can also compare it with vanilla algorithm."
      ],
      "metadata": {
        "id": "uA40t57WUt7N"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3rfSVHIlatrw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}