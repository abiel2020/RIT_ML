{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Homework 3: Gradien Descent and Model (parameters/features) Selection (20pt)"
      ],
      "metadata": {
        "id": "-WFKD1qwG9yQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKp6ahFt4vIa"
      },
      "outputs": [],
      "source": [
        "#from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#from matplotlib import cm\n",
        "#%matplotlib inline\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from IPython.display import clear_output\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the dataset from class, missing values imputed for you"
      ],
      "metadata": {
        "id": "KuAyXCmEGCNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\",\n",
        "                    header=None, na_values=[\"?\"])\n",
        "Data.dropna(subset=Data.columns[Data.columns != 1], inplace=True)\n",
        "imputer = SimpleImputer()\n",
        "Data[1] = imputer.fit_transform(Data[[1]])"
      ],
      "metadata": {
        "id": "cN6SOYFdEUds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.set_option('display.max_columns', None)\n",
        "Data.head()"
      ],
      "metadata": {
        "id": "bhAVOjNtG0QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We itroduced Stochastic Gradien Descent algorithm:\n",
        "\n",
        "1) Initialize randomly weights $w=(w_0, w_1, \\ldots, w_d)$\n",
        "\n",
        "2) Take a point $x^{(i)}=(x_0^{(i)}, x_1^{(i)}, \\ldots, x_d^{(i)})$ with $x_0^{(i)}=1$\n",
        "\n",
        "3) Calculate error (MSE) on it:\n",
        "$$Loss(a(x^{(i)}), y^{(i)}) = (w^Tx^{(i)} - y^{(i)})^2$$\n",
        "\n",
        "4) Calculate gradient of the loss function:\n",
        "$$\\nabla Loss(a(x^{(i)}), y^{(i)}) = 2x^{(i)}(w^Tx^{(i)} - y^{(i)})\\qquad (*)$$\n",
        "\n",
        "5) Update weights:\n",
        "$$\n",
        "w^{new} = w^{old} - \\nabla Loss(a(x^{(i)}), y^{(i)})\n",
        "$$"
      ],
      "metadata": {
        "id": "38I3k29pEA52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Derivation of the expression $(*)$.* The loss function looks as follows:\n",
        "$$Loss(a(x^{(i)}), y^{(i)})=(w_0x_0^{(i)}+w_1x_1^{(i)}+\\ldots+w_dx_d^{(i)} - y^{(i)})^2$$\n",
        "Gradient is a vector of derivatives with respect to every $w_j:$\n",
        "$$\\nabla (w_0x_0^{(i)}+w_1x_1^{(i)}+\\ldots+w_dx_d^{(i)} - y^{(i)})^2\n",
        "= \\begin{pmatrix}2x_0^{(i)}(w_0x_0^{(i)}+w_1x_1^{(i)} + \\ldots +w_dx_d^{(i)} - y^{(i)}) \\\\ 2x_1^{(i)}(w_0x_0^{(i)}+w_1x_1^{(i)} + \\ldots +w_dx_d^{(i)} - y^{(i)})\\\\ \\vdots \\\\ 2x_d^{(i)}(w_0x_0^{(i)}+w_1x_1^{(i)}+\\ldots+w_dx_d^{(i)} - y^{(i)})\\end{pmatrix}$$\n",
        "$$= \\begin{pmatrix}2x_0^{(i)} \\\\ 2x_1^{(i)}\\\\ \\vdots \\\\ 2x_d^{(i)}\\end{pmatrix} (w_0x_0^{(i)}+w_1x_1^{(i)}+\\ldots+w_dx_d^{(i)} - y^{(i)}) =2x^{(i)}(w^Tx^{(i)} - y^{(i)})$$"
      ],
      "metadata": {
        "id": "an7ekya6WHq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. (7pt) A class with realization of SGD algorithm is provided below. There is a parameter *batch_size=1.* You are asked to add code, such that for *batch_size=B>1* it performes mini-batch SGD and for *batch_size=0* it peformes standard Gradient Descent using full batch.  "
      ],
      "metadata": {
        "id": "gnt41iEFWOVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do not use $sum()$ at all. For example, to compute the loss over all the data, we use matrix nodation\n",
        "$$\n",
        "\\sum_{i=1}^{N}(w^Tx^{(i)}-y^{(i)})^2=\\frac{1}{N}(Xw-y)^T(Xw-y)\n",
        "$$\n",
        "that can be coded as\n",
        "``(X.dot(w)-y).dot(X.dot(w)-y)/len(y)``.\n",
        "\n",
        "You can get some ideas from [the class notebook](https://github.com/anton-selitskiy/RIT_ML/blob/main/2024_spring/Lectures/ML5.ipynb)"
      ],
      "metadata": {
        "id": "Jk1R9Ygyen0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD():\n",
        "  def __init__(self, batch_size=1, lr=1e-3, max_epoch=100):\n",
        "    self.batch_size = batch_size\n",
        "    self.lr = lr\n",
        "    self.max_epoch = max_epoch\n",
        "\n",
        "\n",
        "  def loss(self, x, y):\n",
        "    return (x.dot(self.w)-y)**2\n",
        "\n",
        "  def loss_grad(self, x, y):\n",
        "    return 2*(x*(self.w)-y)\n",
        "\n",
        "  def batch_loss(self, X, y):\n",
        "    #your code here\n",
        "    pass\n",
        "\n",
        "  def batch_loss_grad(self, X, y):\n",
        "    #your code here\n",
        "    pass\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.X = np.hstack((np.ones((len(X),1)),X.values))\n",
        "    self.y = y.values\n",
        "    self.w = np.random.rand(self.X.shape[1])\n",
        "    for epoch in range(self.max_epoch):\n",
        "      if self.batch_size == 1:\n",
        "        for i in range(len(self.X)):\n",
        "          self.w -= self.lr*self.loss_grad(self.X[i,:], self.y[i])\n",
        "      else:\n",
        "        #self.batch_size == 0 or >1\n",
        "        #your code here\n",
        "        pass\n",
        "\n",
        "      # Uncomment for Visualisation\n",
        "      # if (epoch + 1) % 10 == 0:\n",
        "      #   clear_output(True)\n",
        "      #   plt.figure(figsize=(10,8))\n",
        "      #   plt.scatter(self.X[:,1], self.y, label=\"data\")\n",
        "      #   plt.scatter(self.X[:,1], self.X.dot(self.w), color=\"orange\", linewidth=5, label=\"predictions\")\n",
        "      #   plt.xlabel(\"Feature 13\", fontsize=14)\n",
        "      #   plt.ylabel(\"Car Price\", fontsize=14)\n",
        "      #   plt.title(f\"SGD batch size = {self.batch_size}, epoch = {epoch}, lr={self.lr}, RMSE={np.sqrt(sgd.batch_loss(sgd.X,sgd.y))}\", fontsize=18)\n",
        "      #   plt.legend(fontsize=14)\n",
        "      #   plt.show()"
      ],
      "metadata": {
        "id": "B1C7uJBg5Ced"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. (3pt) Run this class with the following parameters:\n",
        "\n",
        "max_epochs = 100 and 1000\n",
        "\n",
        "batch_size = 0, 1, 10, 50\n",
        "\n",
        "lr = 1e-6, 1e-7, 1e-8\n",
        "\n",
        "Report the results (RMSE) and try to explain how batch size coordinates with the learning rate."
      ],
      "metadata": {
        "id": "oUNyzWLigM2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "xk1ofIqJocqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = SGD(max_epoch=100, lr=1e-6, batch_size=1)"
      ],
      "metadata": {
        "id": "FlJJihWnAo8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd.fit(Data[[13]],Data[25])"
      ],
      "metadata": {
        "id": "1MpMSiA6A2na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed()"
      ],
      "metadata": {
        "id": "wGbN6W4YFQJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd.w"
      ],
      "metadata": {
        "id": "lYvE9F0zwXu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. (10pt) In this part you will use built-in functions for Linear Regression that are using SGD under the hood.\n",
        "\n",
        "(1pt) Plot the histograms for numerical data and bar-plots for categorical features, add $x$ axis name (file Description.txt). You can get the names of the columns as follows:\n",
        "```\n",
        "# List of numerical columns (assuming they have numeric data types)\n",
        "numerical_columns = Data.select_dtypes(exclude=['object']).columns.tolist()\n",
        "\n",
        "# List of nominal (categorical) columns (assuming they have object data types)\n",
        "nominal_columns = Data.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "```\n",
        "And then methods\n",
        "```\n",
        "Data[column].hist()\n",
        "Data[column].value_counts().plot(kind='bar')\n",
        "```\n",
        "\n",
        "(1pt) Transform categorical data into numerical ([see SGD notebook](https://github.com/anton-selitskiy/RIT_ML/blob/main/2024_spring/Lectures/ML5.ipynb)).\n",
        "\n",
        "(3pt) Choose the features for prediction ([see Model Selection notebook](https://github.com/anton-selitskiy/RIT_ML/blob/main/2024_spring/Lectures/ML6.ipynb))\n",
        "\n",
        "(3pt) Choose the model by the greed-search (using validation set or cross-validation)\n",
        "\n",
        "(2pt) Train the best model and report it's performance on the Test set. Justify your choice of the metric for evaluation."
      ],
      "metadata": {
        "id": "sWgZF7pghsC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To have the names of the columns, we upload file Description.txt\n",
        "descripsion = pd.read_csv('https://raw.githubusercontent.com/anton-selitskiy/RIT_ML/main/2024_spring/Homeworks/Description.txt', delimiter=':', header=None)\n",
        "Data.columns = descripsion[0].str.strip() #delete extra spaces in the column names\n",
        "Data.head()"
      ],
      "metadata": {
        "id": "NQsFUcZSfYZO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oor__VvceAXE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}